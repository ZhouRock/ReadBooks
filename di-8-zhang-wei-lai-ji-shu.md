# 第8章：未来技术

在前面有关多处理器处理的各节中，我们已经看到，如果按比例增加CPU或内核的数量，则必须预料到明显的性能问题。但是，这种扩展正是未来所期望的。处理器将拥有越来越多的内核，并且程序必须越来越并行以利用CPU潜力的增加，因为单核性能不会像以前那样迅速地提高。

## 8.1 原子操作问题

传统上，同步访问共享数据结构的方式有两种：

* * 通过互斥，通常通过使用系统运行时的功能来实现这一目标；
* 通过使用无锁数据结构。

无锁数据结构的问题在于，处理器必须提供可以原子地执行整个操作的原语。这种支持是有限的。在大多数体系结构上，支持仅限于原子地读写一个词。有两种基本方法可以实现此目的（请参见第6.4.2节）：

* * 使用原子比较和交换（CAS）操作；
* 使用加载锁定/存储条件（LL / SC）对。

可以很容易地看出如何使用LL / SC指令实现CAS操作。这使CAS操作成为大多数原子操作和无锁数据结构的构建块。

一些处理器，尤其是x86和x86-64体系结构，提供了更为详尽的原子操作集。其中许多是针对特定目的的CAS操作的优化。例如，可以使用CAS和LL / SC操作以原子方式将值添加到内存位置，但是对x86 / x86-64处理器上原子增量的本机支持更快。对于程序员而言，重要的是要了解这些操作以及使它们在编程时可用的内在函数，但这并不是什么新鲜事物。

这两种体系结构的非凡扩展是它们具有双字CAS（DCAS）操作。这对于某些应用程序（但不是全部）很重要（请参阅\[dcas\]）。作为如何使用DCAS的示例，让我们尝试编写基于阵列的无锁堆栈/ LIFO数据结构。在图8.1中可以看到使用gcc内在函数的第一次尝试。

> ```text
>   struct elem {
>     data_t d;
>     struct elem * c;
>   };
>   struct elem * top;
>   无效推（struct elem * n）{
>     n-> c =顶部；
>     顶部= n;
>   }
>   struct elem * pop（void）{
>     struct elem * res = top;
>     如果（res！= NULL）
>       顶部= res-> c;
>     返回资源；
>   }
> ```
>
> **图8.1：不是线程安全的LIFO**

这段代码显然不是线程安全的。不同线程中的并发访问将修改全局变量top，而无需考虑其他线程的修改。元素可能丢失或被删除，元素可以神奇地重新出现。可以使用互斥，但在这里我们将尝试仅使用原子操作。

解决此问题的首次尝试是在安装或删除列表元素时使用CAS操作。生成的代码如图8.2所示。

> ```text
>   ＃定义CAS __sync_bool_compare_and_swap
>   struct elem {
>     data_t d;
>     struct elem * c;
>   };
>   struct elem * top;
>   无效推（struct elem * n）{
>     做
>       n-> c =顶部；
>     while（！CAS（＆top，n-> c，n））;
>   }
>   struct elem * pop（void）{
>     struct elem * res;
>     而（（res = top）！= NULL）
>       如果（CAS（＆top，res，res-> c））
>         休息;
>     返回资源；
>   }
> ```
>
> **图8.2：使用CAS的LIFO**

乍一看，这似乎是一个可行的解决方案。 顶部绝不会被修改，除非它这是在LIFO的顶部的操作开始时的元素相匹配。但是我们必须考虑所有级别的并发性。可能是在最坏的时刻安排了另一个在数据结构上工作的线程。这里的一种情况就是所谓的ABA问题。请考虑一下，如果在弹出窗口中的CAS操作之前安排了第二个线程并执行以下操作，将会发生什么情况：

1. l = pop（）
2. 推（newelem）
3. 推（l）

此操作的最终结果是，LIFO的前一个顶部元素返回顶部，但第二个元素不同。返回第一个线程，因为top元素不变，所以CAS操作将成功。但是，值res-&gt; c不合适。它是原始LIFO的第二个元素的指针，而不是newelem的指针。结果是这个新元素丢失了。

在\[lockfree\]文献中，您找到了使用某些处理器上的功能来解决此问题的建议。具体地说，这与x86和x86-64处理器执行DCAS操作的能力有关。这在图8.3的代码的第三种形式中使用。

> ```text
>   ＃定义CAS __sync_bool_compare_and_swap
>   struct elem {
>     data_t d;
>     struct elem * c;
>   };
>   struct lifo {
>     struct elem * top;
>     size_t gen;
>   } l;
>   无效推（struct elem * n）{
>     struct lifo旧，新；
>     做 {
>       旧= l;
>       new.top = n-> c = old.top;
>       new.gen = old.gen +1;
>     } while（！CAS（＆l，old，new））;
>   }
>   struct elem * pop（void）{
>     struct lifo旧，新；
>     做 {
>       旧= l;
>       如果（old.top == NULL）返回NULL;
>       new.top = old.top-> c;
>       new.gen = old.gen +1;
>     } while（！CAS（＆l，old，new））;
>     返回old.top;
>   }
> ```
>
> **图8.3：使用双字CAS的LIFO**

与其他两个示例不同，这是（当前）伪代码，因为gcc不会破坏CAS内部函数中结构的使用。无论如何，该示例应该足以理解该方法。将生成计数器添加到指向LIFO顶部的指针。由于在每次操作push或pop时都会对其进行更改，因此上述ABA问题不再是问题。到第一个线程通过实际交换顶部 指针恢复工作时，生成计数器已经增加了三倍。CAS操作将失败，并且在循环的下一轮中，将确定LIFO的正确的第一和第二元素，并且LIFO不会损坏。Voilà。

这真的是解决方案吗？\[freefree\]的作者肯定听起来像这样，值得称赞的是，有可能为LIFO构造数据结构，这将允许使用上面的代码。但是，总的来说，这种方法注定会像前一种方法一样注定要失败。只是在另一个地方，我们仍然存在并发问题。让我们假设一个线程执行pop 并在测试old.top == NULL之后被中断。现在，第二个线程使用pop并获得了LIFO先前的第一个元素的所有权。它可以执行任何操作，包括更改所有值，或者在动态分配元素的情况下，释放内存。

现在，第一个线程恢复。在旧变量仍然充满了后进先出法的前顶部。更具体地说，顶部 成员指向第二个线程弹出的元素。在 new.top = old.top-&gt; c中第一个线程取消引用元素中的指针。但是此指针引用的元素可能已释放。地址空间的那部分可能无法访问，并且进程可能崩溃。对于通用数据类型实现，这是不允许的。解决此问题的方法非常昂贵：绝不能释放内存，或者至少必须在释放之前验证没有线程再引用该内存。假定无锁数据结构应该更快，更并发，那么这些额外的要求将完全破坏任何优势。在支持它的语言中，通过垃圾回收处理内存可以解决问题，但这要付出代价。

对于更复杂的数据结构，情况通常更糟。上面引用的同一篇论文还描述了FIFO实现（在后续文章中进行了改进）。但是此代码具有所有相同的问题。由于在现有硬件（x86，x86-64）上的CAS操作仅限于修改在内存中连续的两个字，因此在其他常见情况下它们根本无济于事。例如，不可能在双向链接列表中的任何位置自动添加或删除元素。{作为旁注，IA-64的开发人员 未包含此功能。它们允许比较两个单词，但只能替换一个单词。}

问题是通常涉及多个内存地址，并且只有这些地址的值均未同时更改时，整个操作才能成功。这是数据库处理中的一个众所周知的概念，而这正是解决这一难题的最有希望的提议之一。

## 8.2 交易记忆

Herlihy和Moss在其开创性的1993年论文\[transactmem\]中提出，要实现硬件中的内存操作事务，因为仅靠软件不能有效地解决问题。当时的数字设备公司（Digital Equipment Corporation）已经在其高端硬件（具有几十个处理器）上应对可扩展性问题。原理与数据库事务相同：事务的结果立即变为可见，或者事务中止并且所有值保持不变。

这就是内存发挥作用的地方，也是上一节为什么费心开发使用原子运算的算法的原因。在许多情况下，尤其是对于无锁数据结构，事务性内存是原子操作的替代和扩展。将事务处理系统集成到处理器中听起来很困难，但是实际上，大多数处理器在某种程度上已经具有类似的功能。

由某些处理器实现的LL / SC操作形成一个事务。SC指令根据是否触摸了内存位置来中止或提交事务。事务性内存是此概念的扩展。现在，代替一对简单的指令，而是多个指令参与了交易。要了解它是如何工作的，值得首先了解如何实现LL / SC指令。{这并不意味着它实际上是这样实现的。}

### 8.2.1  加载锁定/存储条件实现

如果发出LL指令，则将存储单元的值加载到寄存器中。作为该操作的一部分，该值将被加载到L1d中。如果未修改此值，则稍后SC指令才能成功。处理器如何检测到这一点？回顾图3.18中对MESI协议的描述，答案应该显而易见。如果另一个处理器更改了内存位置的值，则必须撤消第一个处理器的L1d中的值的副本。当在第一个处理器上执行SC指令时，它将发现它必须再次将该值加载到L1d中。这是处理器必须已经检测到的东西。

关于上下文切换（可能在同一处理器上进行修改）以及在另一处理器上进行写操作后意外重载高速缓存行，还有一些其他细节需要解决。这是无法解决的策略（上下文切换上的缓存刷新）和额外的标志，或LL / SC指令的单独缓存行无法解决的问题。通常，LL / SC实现几乎是免费提供的，例如MESI这样的缓存一致性协议的实现。

###  **8.2.2事务性内存操作**

为了使事务性存储大体上有用，不得使用第一个存储指令来完成事务。相反，实现应允许一定数量的加载和存储操作。这意味着我们需要单独的提交和中止指令。稍后，我们将看到我们还需要一条指令，该指令可以检查事务的当前状态以及它是否已经中止。

要实现三种不同的内存操作：

* 读取内存
* 读取稍后写入的内存
* 写内存

在查看MESI协议时，应该清楚这种特殊的第二种读取操作如何有用。正常读取可以通过处于“ E”和“ S”状态的高速缓存行来满足。第二种类型的读取操作需要状态为“ E”的高速缓存行。从下面的讨论中可以确切地知道为什么需要第二种类型的内存读取，但是对于更完整的描述，有兴趣的读者可以从\[transactmem\]开始参考有关事务性内存的文献。

另外，我们需要事务处理，它主要由数据库事务处理中已经熟悉的提交和中止操作组成。不过，还有另一种操作，从理论上讲是可选的，但使用事务性内存编写健壮的程序则需要此操作。该指令使线程可以测试事务是否仍在进行中，并且可以（也许）稍后进行提交，或者事务是否已经失败并且在任何情况下都将中止。

我们将讨论这些操作实际上如何与CPU缓存交互以及它们如何与总线操作匹配。但是在我们这样做之前，我们先看一些使用事务性内存的实际代码。希望这会使本节的其余部分更容易理解。

###  **8.2.3使用事务性内存的示例代码**

对于该示例，我们将重新查看正在运行的示例，并显示一个使用事务性内存的LIFO实现。

> ```text
>   struct elem {
>     data_t d;
>     struct elem * c;
>   };
>   struct elem * top;
>   无效推（struct elem * n）{
>     而（1）{
>       n-> c = LTX（top）;
>       ST（＆top，n）;
>       如果（COMMIT（））
>         返回;
>       ... 延迟 ...
>     }
>   }
>   struct elem * pop（void）{
>     而（1）{
>       struct elem * res = LTX（top）;
>       如果（VALIDATE（））{
>         如果（res！= NULL）
>           ST（＆top，res-> c）;
>         如果（COMMIT（））
>           返回资源；
>       }
>       ... 延迟 ...
>     }
>   }
> ```
>
> **图8.4：LIFO使用事务性内存**

该代码看起来与非线程安全代码非常相似，这是一个额外的好处，因为它使使用事务性内存编写代码更加容易。该代码的新部分是LTX，ST， COMMIT和VALIDATE操作。这四个操作是请求访问事务性存储器的方式。实际上还有另外一个操作LT，这里不使用。 LT请求非独占读访问，LTX请求独占读访问，ST是存储在事务内存中的存储。该VALIDATEoperation是检查事务是否仍在进行中的操作。如果此事务仍然正常，则返回true。如果该事务已被标记为正在中止，则它将实际上被中止，并且下一条事务存储指令将开始一个新的事务。因此，如果事务仍在进行，则代码使用新的if块。

该COMMIT操作完成交易; 如果事务成功完成，则操作返回true。这意味着程序的这一部分已经完成，线程可以继续前进。如果该操作返回错误值，这通常意味着必须重复整个代码序列。这就是外部while 循环在这里执行的操作。这并不是绝对必要的，但是在某些情况下，放弃工作是正确的选择。

关于LT，LTX和ST 操作的有趣之处在于，它们可以失败而不会以任何直接的方式发出信号通知此失败。程序可以通过VALIDATE或COMMIT操作来请求此信息。对于加载操作，这可能意味着实际加载到寄存器中的值可能是伪造的。这就是为什么在上面的示例中必须使用 VALIDATE的原因在取消引用指针之前。在下一节中，我们将了解为什么这是实现的明智选择。可能是，一旦事务内存实际上广泛可用，处理器就会实现一些不同的东西。不过，\[transactmem\]的结果表明了我们在此处描述的内容。

该推送功能可以概括为这样的：交易是通过读取指针链表的头开始。读取请求排他所有权，因为在该函数的后面，写入了该变量。如果另一个线程已经启动了一个事务，则加载将失败，并将仍然存在的事务标记为已中止；在这种情况下，实际加载的值可能是垃圾。不论其状态如何，该值都存储在下一个新列表成员的字段。这很好，因为该成员尚未使用，并且只能由一个线程访问。然后将指向列表开头的指针分配给新元素的指针。如果事务仍然正常，则此写入可以成功。这是正常情况，只有在线程使用所提供的push和 pop函数以外的其他代码来访问此指针时，它才会失败。 如果交易在ST时已经中止被执行，什么也不做。最后，线程尝试提交事务。如果成功，那么工作就完成了；其他线程现在可以开始其事务。如果事务失败，则必须从头开始重复。但是，在此之前，最好插入一个延迟。如果不这样做，线程可能会在繁忙的循环中运行（浪费能量，导致CPU过热）。

该弹出功能稍微复杂一些。它还从读取包含列表开头的变量开始，请求排他所有权。然后，代码立即检查LTX操作是否 成功。如果不是这样，则本轮除了延迟下一轮外，不会做其他任何事情。如果成功读取了顶部指针，则表示其状态为良好；否则，状态为0。我们现在可以取消引用指针。记住，这正是使用原子操作的代码的问题。有了事务性内存，这种情况就可以毫无问题地处理了。以下ST仅当LIFO不为空时才执行操作，就像原始的线程不安全代码一样。最后，交易被提交。如果成功，函数将旧指针返回到头部；否则，函数将返回原来的指针。否则，我们将延迟并重试。该代码的一个棘手的部分是要记住，如果VALIDATE操作已经失败，它将中止该事务。下一个事务性存储操作将启动一个新的事务，因此，我们必须跳过该函数中的其余代码。

当硬件中可用事务存储实现时，将看到延迟代码如何工作。如果做得不好，系统性能可能会受到很大影响。

###  **8.2.4事务性存储器的总线协议**

既然我们已经了解了事务存储背后的基本原理，那么我们就可以深入研究实现的细节。请注意，这 不是基于实际的硬件。它基于事务性存储器的原始设计和有关缓存一致性协议的知识。省略了一些细节，但仍然应该有可能深入了解性能特征。

事务性内存实际上并未实现为单独的内存；考虑到需要在线程的地址空间中任何位置进行事务，这毫无意义。相反，它是在第一个缓存级别实现的。从理论上讲，该实现可以在正常的L1d中进行，但是，正如\[transactmem\]所指出的那样，这不是一个好主意。我们将更有可能看到与L1d并行实现的事务缓存。所有访问将以与使用L1d相同的方式使用更高级别的缓存。事务缓存可能比L1d小得多。如果它是完全关联的，则其大小由事务可包含的操作数确定。实施可能会限制体系结构和/或特定处理器版本。可以轻松想象一个包含16个甚至更少元素的事务缓存。在上面的示例中，我们只需要一个存储位置；具有较大事务工作集的算法变得非常复杂。我们可能会看到处理器在任何时候都支持多个活动事务。然后，高速缓存中的元素数量成倍增加，但是它仍然足够小，可以完全关联。

事务缓存和L1d是互斥的。这意味着，一条高速缓存行最多位于其中一个高速缓存中，而从不在两个高速缓存中。事务高速缓存中的每个插槽在任何时候都处于四个MESI协议状态之一。除此之外，插槽还具有事务状态。状态如下（根据\[transactmem\]命名）：

**空的**高速缓存插槽中没有数据。MESI状态始终为“ I”。

**普通的**高速缓存插槽中包含已提交的数据。数据也可能存在于L1d中。MESI状态可以是“ M”，“ E”和“ S”。允许使用“ M”状态的事实意味着事务提交 不会强制将数据写入主内存（除非将内存区域声明为未缓存或直写）。这可以极大地帮助提高性能。

**XABORT**高速缓存插槽中包含中止时会丢弃的数据。这显然与XCOMMIT相反。在事务期间创建的所有数据都保存在事务缓存中，在提交之前不会将任何内容写入主内存。这限制了最大事务大小，但是这意味着，除了事务缓存之外，其他任何内存都不必知道单个内存位置的XCOMMIT / XABORT对偶性。可能的MESI状态为“ M”，“ E”和“ S”。

**XCOMMIT**高速缓存插槽中包含在提交时被丢弃的数据。这是处理器可以实现的可能的优化。如果使用事务操作更改了内存位置，则不能仅删除旧内容：如果事务失败，则需要恢复旧内容。MESI状态与XABORT相同。关于XABORT的一个区别是，如果事务高速缓存已满，则可以将任何处于“ M”状态的XCOMMIT条目写回到内存，然后对于所有状态都将其丢弃。

当LT操作开始时，处理器会在高速缓存中分配两个插槽。通过首先为操作的地址（即高速缓存命中）寻找NORMAL插槽来选择受害者。如果找到这样的条目，则找到第二个插槽，复制值，将一个条目标记为XABORT，将另一个标记为XCOMMIT。

如果该地址尚未缓存，则将找到EMPTY缓存槽。如果找不到，则寻找NORMAL插槽。如果MESI状态为“ M”，则必须将旧内容刷新到内存中。如果也没有NORMAL插槽，则可能会损害XCOMMIT条目。不过，这很可能是实现细节。事务的最大大小由事务高速缓存的大小确定，并且由于事务中每个操作所需的插槽数是固定的，因此可以在不必退出XCOMMIT条目之前限制事务数。

如果在事务高速缓存中找不到该地址，则会在总线上发出T\_READ请求。这就像普通的READ总线请求一样，但是它表明这是用于事务性缓存的。就像普通的READ请求一样，所有其他处理器中的缓存都首先有机会做出响应。如果没有，则从主存储器读取该值。MESI协议确定新缓存行的状态是“ E”还是“ S”。当另一个处理器或内核上的活动事务当前正在使用高速缓存行时，T\_READ和READ之间的区别就会发挥作用。在这种情况下，T\_READ操作显然会失败，因此不会传输任何数据。生成T\_READ总线请求的事务被标记为失败，并且操作中使用的值（通常是简单的寄存器加载）未定义。回顾示例，我们可以看到，如果正确使用事务性内存操作，则此行为不会引起问题。在使用加载到事务中的值之前，必须使用进行验证验证。几乎在任何情况下，这都是一个额外的负担。正如我们在尝试使用原子操作创建FIFO实现中所看到的那样，我们添加的检查是使无锁代码正常工作的一项缺失功能。

所述LTX操作几乎是相同的LT。一个区别是总线操作是T\_RFO而不是T\_READ。像普通的RFO总线请求一样，T\_RFO请求高速缓存行的排他所有权。生成的高速缓存行的状态为“ E”。像T\_READ总线请求一样，T\_RFO也会失败，在这种情况下，使用的值也是未定义的。如果高速缓存行已经在本地事务高速缓存中，处于“ M”或“ E”状态，则无需执行任何操作。如果本地事务缓存中的状态为“ S”，则总线请求必须退出以使所有其他副本无效。

在ST操作类似于LTX。首先使该值在本地事务缓存中排他性可用。然后， ST操作将值的副本复制到缓存中的第二个插槽中，并将该条目标记为XCOMMIT。最后，另一个插槽被标记为XABORT，并将新值写入其中。如果事务已被中止，或者由于隐式LTX 失败而被新中止，则不会写入任何内容。

VALIDATE或COMMIT 均不自动操作会隐式创建总线操作。这是事务性内存比原子操作具有的巨大优势。使用原子操作，可以通过将更改的值写回到主存储器中来实现并发。如果您到目前为止已经阅读了本文档，则应该知道它的价格是多少。使用事务性内存时，不会强制访问主内存。如果高速缓存中没有EMPTY插槽，则必须清除当前内容，对于处于“ M”状态的插槽，必须将内容写入主内存。这与常规缓存没有什么不同，并且可以在没有特殊原子性保证的情况下执行回写。如果缓存大小足够，则内容可以生存很长时间。如果一次又一次地在相同的内存位置上执行事务，

对于中止的事务， 所有VALIDATE和COMMIT操作都将标记为XABORT的缓存插槽标记为空，并将XCOMMIT插槽标记为NORMAL。同样，当COMMIT 成功完成事务时，XCOMMIT插槽标记为空，而XABORT插槽标记为NORMAL。这些是对事务缓存的非常快速的操作。没有显式通知其他要执行事务的处理器；这些处理器只需要继续尝试。有效地做到这一点是另一回事。在上面的示例代码中，我们只是 在适当的位置放置了... delay...。我们可能会看到实际的处理器支持以一种有用的方式来进行延迟。

总而言之，事务性内存操作仅在启动新事务并且将尚未在事务高速缓存中的新高速缓存行添加到仍成功的事务中时才引起总线操作。中止的事务中的操作不会导致总线操作。由于有多个线程试图使用同一内存，因此不会有缓存行乒乓。

###  **8.2.5其他考虑**

在6.4.2节中，我们已经讨论了在某些情况下如何使用x86和x86-64上可用的锁前缀来避免原子操作的编码。但是，当有多个线程在使用不争夺同一内存的线程时，建议的技巧就不够了。在这种情况下，不必要使用原子操作。有了事务性内存，这个问题就消失了。仅当同时或连续在不同CPU上使用内存时，才会发出昂贵的RFO总线请求。只有在需要它们的情况下才如此。做得更好几乎是不可能的。

细心的读者可能对延迟感到好奇。预期的最坏情况是什么？如果对具有活动事务的线程进行了调度，或者接收到信号并可能终止了该线程，或者决定使用siglongjmp跳转到外部作用域，该怎么办？答案是：事务将中止。每当线程进行系统调用或接收信号（即发生环级更改）时，就有可能中止事务。在执行系统调用或处理信号时，中止事务也可能是操作系统的职责之一。我们将不得不等到实现可用后才能看到实际完成的工作。

事务存储的最后一个方面应该在这里进行讨论，即使在今天，人们仍可能要考虑这些问题。事务高速缓存与其他高速缓存一样，在高速缓存行上运行。由于事务缓存是专用缓存，因此使用相同的缓存行进行事务和非事务操作将是一个问题。因此，重要的是

* * 将非事务性数据移出缓存行
* 具有用于单独事务中的数据的单独缓存行

第一点不是新问题，同样的努力将为今天的原子操作带来回报。第二个问题更大，因为由于相关的高成本，如今对象几乎从未与高速缓存行对齐。如果使用的数据以及使用原子操作修改过的单词在同一高速缓存行上，则需要少一个高速缓存行。这不适用于互斥（互斥对象应始终具有自己的缓存行），但是可以肯定的是，原子操作会与其他数据一起出现。对于事务性内存，将高速缓存行用于两个目的将很可能是致命的。每次对数据的正常访问{来自相关的缓存行。访问任意其他高速缓存行不会影响事务。}将从事务缓存中删除缓存行，从而中止该事务。将来，数据对象的缓存对齐将不仅是性能问题，而且是正确性问题。

事务性内存实现可能会使用更精确的计费方式，因此可能不会正常访问作为事务一部分的高速缓存行上的数据。但是，这需要付出更多的努力，因为从那时起，MESI协议信息已不再足够。

## 8.3增加延迟

关于存储器技术的未来发展的一件事几乎可以肯定：延迟将继续上升。在第2.2.4节中，我们已经讨论了即将到来的DDR3内存技术将比当前的DDR2技术具有更高的延迟。如果应该部署FB-DRAM，则FB-DRAM的潜在延迟也可能更高，尤其是当FB-DRAM模块以菊花链方式连接时。传递请求和结果不是免费的。

延迟的第二个来源是NUMA的使用越来越多。如果AMD的Opteron具有多个处理器，则它们是NUMA机器。通过其自己的内存控制器将一些本地内存附加到CPU，但是在SMP主板上，其余的内存必须通过Hypertransport总线进行访问。英特尔的CSI技术将使用几乎相同的技术。由于每个处理器的带宽限制以及保持（例如）多个10Gb / s以太网端口繁忙的要求，即使每个插槽的内核数量增加，多插槽主板也不会消失。

延迟的第三个来源是协处理器。我们认为，在1990年代初不再需要用于商品处理器的数学协处理器之后，我们就摆脱了它们，但是它们正在卷土重来。英特尔的Geneseo和AMD的Torrenza是该平台的扩展，允许第三方硬件开发人员将其产品集成到主板中。即，协处理器将不必坐在PCIe卡上，而是位于更靠近CPU的位置。这给了他们更多的带宽。

IBM在Cell CPU上走了一条不同的路线（尽管仍然可以进行像Intel和AMD这样的扩展）。除PowerPC内核外，Cell CPU还包括8个协同处理单元（SPU），它们是主要用于浮点计算的专用处理器。

协处理器和SPU的共同点是，它们最有可能比实际处理器具有更慢的内存逻辑。这部分是由于必要的简化所致：所有缓存的处理，预取等都很复杂，尤其是在还需要缓存一致性的情况下。高性能程序将越来越依赖于协处理器，因为性能差异可能很大。单元CPU的理论峰值性能为210 GFLOPS，而高端CPU的理论峰值性能为50-60 GFLOPS。当今使用的图形处理单元（GPU，图形卡上的处理器）达到了更高的数量（超过500 GFLOPS），并且可能不费吹灰之力就可以将其集成到Geneseo / Torrenza系统中。

所有这些发展的结果是，程序员必须得出结论，预取将变得越来越重要。对于协处理器而言，这绝对是至关重要的。对于CPU（尤其是具有越来越多的内核）的CPU，有必要始终保持FSB繁忙，而不是分批堆积请求。这就要求CPU通过有效使用预取指令来尽可能深入地了解将来的流量。

## 8.4向量运算

当今主流处理器中的多媒体扩展仅以有限的方式实现矢量操作。向量指令的特点是可以一起执行大量的操作。与标量运算相比，这可以说是关于多媒体指令的，但与矢量计算机（如Cray-1）或矢量单元（如IBM 3090）所做的工作相差甚远。

为了补偿为一条指令执行的有限数量的操作（大多数机器上为四个 浮点或两个 双精度运算），必须更频繁地执行周围的循环。9.1节中的示例清楚地说明了这一点，每个高速缓存行都需要SM迭代。

使用更宽的向量寄存器和操作，可以减少循环迭代的次数。这不仅可以改善指令解码等。在这里，我们对记忆效应更感兴趣。通过单个指令加载或存储更多数据，处理器可以更好地了解应用程序的内存使用情况，而不必尝试将各个指令的行为中的信息拼凑在一起。此外，提供不影响高速缓存的加载或存储指令变得更加有用。在x86 CPU中使用16字节宽的SSE寄存器加载时，使用未缓存的加载是个坏主意，因为以后对同一缓存行的访问必须再次从内存中加载数据（如果发生缓存丢失）。另一方面，如果 向量寄存器足够宽，可以容纳一个或多个缓存行，未缓存的负载或存储不会产生负面影响。对不适合高速缓存的数据集执行操作变得更加实际。

具有大的向量寄存器并不一定意味着指令的等待时间会增加。向量指令不必等待读取或存储所有数据。如果矢量单元可以识别代码流，则可以从已经读取的数据开始。这意味着，例如，如果要加载矢量寄存器，然后将所有矢量元素乘以标量，则一旦加载了矢量的第一部分，CPU便可以开始乘法操作。这仅仅是向量单位的复杂性问题。这表明，从理论上讲，向量寄存器可以真正地变宽，并且考虑到这一点，现在可以潜在地设计程序。在实践中，由于处理器用于多进程和多线程OS中，因此矢量寄存器的大小受到限制。因此，上下文切换时间非常重要，其中包括存储和加载寄存器值。

对于较宽的向量寄存器，存在一个问题，即操作的输入和输出数据无法按顺序排列在内存中。这可能是因为矩阵是稀疏的，矩阵是由列而不是行访问的，以及许多其他因素。在这种情况下，矢量单元提供了以非顺序模式访问内存的方法。可以对单个向量加载或存储进行参数设置，并指示它从地址空间中许多不同的位置加载数据。使用今天的多媒体说明，这是完全不可能的。必须将这些值一一显式地加载，然后将其精巧地组合到一个向量寄存器中。

过去的向量单位具有不同的模式，以允许使用最有用的访问模式：

* * 使用striding，程序可以指定两个相邻向量元素之间的间隙有多大。所有元素之间的间隙必须相同，但是，例如，这很容易允许用一个指令而不是每行一个指令将矩阵的列读入向量寄存器。
* 使用间接，可以创建任意访问模式。加载或存储指令将接收一个指向数组的指针，该数组包含必须加载的实存储器位置的地址或偏移量。

目前尚不清楚在未来版本的主流处理器中我们是否会看到真正的矢量运算的复兴。也许这项工作将降级到协处理器。无论如何，如果我们能够访问矢量操作，正确组织执行此类操作的代码就显得尤为重要。该代码应该是自包含的并且是可替换的，并且接口应该足够通用以有效地应用矢量运算。例如，接口应该允许添加整个矩阵，而不是对行，列甚至元素组进行操作。构建块越大，使用向量运算的机会就越大。

在\[vectorops\]中，作者强烈呼吁恢复向量运算。他们指出了许多优点，并试图揭穿各种神话。但是，它们绘制的图像过于简单。如上所述，较大的寄存器集意味着较高的上下文切换时间，这在通用OS中必须避免。当涉及到上下文切换密集型操作时，请查看IA-64处理器的问题。如果涉及中断，向量操作的执行时间也很长。如果引发中断，则处理器必须停止其当前工作并开始处理中断。之后，它必须恢复执行中断的代码。通常在工作过程中中断指令是个大问题。这不是不可能，但是很复杂。对于长时间运行的指令，这必须发生，或者必须以可重新启动的方式执行指令，因为否则中断响应时间会太长。后者是不可接受的。

就内存访问的对齐而言，向量单元也是宽容的，它决定了所开发的算法。当今的某些处理器（尤其是RISC处理器）需要严格的对齐方式，因此扩展到全矢量操作并不容易。向量操作有很大的潜在优势，尤其是在支持跨步和间接调用时，因此我们希望将来能看到此功能。

